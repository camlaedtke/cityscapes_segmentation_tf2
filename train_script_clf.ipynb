{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import sys\n",
    "import glob\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from tqdm import tqdm\n",
    "\n",
    "import tensorflow as tf\n",
    "import tensorflow_datasets as tfds\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras import mixed_precision\n",
    "from tensorflow.keras.losses import CategoricalCrossentropy\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping\n",
    "from models.hrnet_clf import HRNet_CLF\n",
    "# from models.hrnet_clf_accumilate import HRNet_CLF\n",
    "# from models.hrnet_clf_gn_accumilate import HRNet_CLF_GN\n",
    "from data_loaders import SunLoader\n",
    "\n",
    "K.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "def enable_amp():\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot')\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(physical_devices,\"\\n\")\n",
    "# enable_amp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "img_height = 224\n",
    "img_width = 224\n",
    "n_classes = 362\n",
    "\n",
    "\n",
    "pipeline = SunLoader(\n",
    "    data_dir = \"/workspace/PythonProjects/cityscapes_segmentation_tf2/SUN397\", \n",
    "    bad_imgs_file = 'SUN397_bad_images.txt',\n",
    "    n_classes = n_classes,\n",
    "    img_height = img_height,\n",
    "    img_width = img_width,\n",
    ")\n",
    "\n",
    "image_list = pipeline.get_image_list()\n",
    "label_list = pipeline.get_label_list(image_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "BATCH_SIZE = 64\n",
    "# ACCUM_STEPS = 4\n",
    "# ADJ_BATCH_SIZE = BATCH_SIZE * ACCUM_STEPS\n",
    "# print(\"Effective batch size: {}\".format(ADJ_BATCH_SIZE))\n",
    "BUFFER_SIZE = 300"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATASET_LENGTH = len(image_list)\n",
    "TRAIN_LENGTH = int(DATASET_LENGTH * 0.7)\n",
    "VALID_LENGTH = int(DATASET_LENGTH * 0.15)\n",
    "TEST_LENGTH = DATASET_LENGTH - (TRAIN_LENGTH+VALID_LENGTH)\n",
    "\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE\n",
    "VALIDATION_STEPS = VALID_LENGTH // BATCH_SIZE"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def display(display_list, title=True):\n",
    "    plt.figure(figsize=(15, 5)) # dpi=200\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_ds = tf.data.Dataset.from_tensor_slices((image_list[:TRAIN_LENGTH], \n",
    "                                               label_list[:TRAIN_LENGTH]))\n",
    "valid_ds = tf.data.Dataset.from_tensor_slices((image_list[TRAIN_LENGTH:-TEST_LENGTH], \n",
    "                                               label_list[TRAIN_LENGTH:-TEST_LENGTH]))\n",
    "\n",
    "train = train_ds.map(pipeline.load_image_train, num_parallel_calls=8)\n",
    "valid = valid_ds.map(pipeline.load_image_test)\n",
    "\n",
    "train_dataset = train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE, drop_remainder=True).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "valid_dataset = valid.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "for image, label in train.take(4): \n",
    "    sample_image, sample_label = image, label\n",
    "\n",
    "print(sample_image.shape, sample_label.shape)\n",
    "display([sample_image])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = HRNet_CLF(\n",
    "    stage1_cfg = {'NUM_MODULES': 1,'NUM_BRANCHES': 1,'BLOCK': 'BOTTLENECK','NUM_BLOCKS': [4]}, \n",
    "    stage2_cfg = {'NUM_MODULES': 1,'NUM_BRANCHES': 2,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4]},\n",
    "    stage3_cfg = {'NUM_MODULES': 4,'NUM_BRANCHES': 3,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4, 4]},\n",
    "    stage4_cfg = {'NUM_MODULES': 3,'NUM_BRANCHES': 4,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4, 4, 4]},\n",
    "    input_height = img_height, \n",
    "    input_width = img_width, \n",
    "    n_classes = n_classes, \n",
    "    W = 48,\n",
    "    # GN_GROUPS=24,\n",
    "    # ACCUM_STEPS=ACCUM_STEPS\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "```python\n",
    "Model: \"HRNet_W48\"\n",
    "_________________________________________________________________\n",
    "Layer (type)                 Output Shape              Param #   \n",
    "=================================================================\n",
    "conv2d (Conv2D)              multiple                  1728      \n",
    "_________________________________________________________________\n",
    "batch_normalization (BatchNo multiple                  256       \n",
    "_________________________________________________________________\n",
    "conv2d_1 (Conv2D)            multiple                  36864     \n",
    "_________________________________________________________________\n",
    "batch_normalization_1 (Batch multiple                  256       \n",
    "_________________________________________________________________\n",
    "re_lu (ReLU)                 multiple                  0         \n",
    "_________________________________________________________________\n",
    "sequential_1 (Sequential)    (1, 128, 256, 192)        168192    \n",
    "_________________________________________________________________\n",
    "sequential_2 (Sequential)    (1, 128, 256, 48)         83136     \n",
    "_________________________________________________________________\n",
    "sequential_4 (Sequential)    (1, 64, 128, 96)          166272    \n",
    "_________________________________________________________________\n",
    "high_resolution_module (High multiple                  880704    \n",
    "_________________________________________________________________\n",
    "sequential_11 (Sequential)   (1, 32, 64, 192)          166656    \n",
    "_________________________________________________________________\n",
    "high_resolution_module_1 (Hi multiple                  3840576   \n",
    "_________________________________________________________________\n",
    "high_resolution_module_2 (Hi multiple                  3840576   \n",
    "_________________________________________________________________\n",
    "high_resolution_module_3 (Hi multiple                  3840576   \n",
    "_________________________________________________________________\n",
    "high_resolution_module_4 (Hi multiple                  3840576   \n",
    "_________________________________________________________________\n",
    "sequential_65 (Sequential)   (1, 16, 32, 384)          665088    \n",
    "_________________________________________________________________\n",
    "high_resolution_module_5 (Hi multiple                  15891072  \n",
    "_________________________________________________________________\n",
    "high_resolution_module_6 (Hi multiple                  15891072  \n",
    "_________________________________________________________________\n",
    "high_resolution_module_7 (Hi multiple                  15891072  \n",
    "_________________________________________________________________\n",
    "sequential_144 (Sequential)  (1, 128, 256, 20)         535700    \n",
    "=================================================================\n",
    "Total params: 65,740,372\n",
    "Trainable params: 65,655,732\n",
    "Non-trainable params: 84,640\n",
    "\n",
    "```"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "MODEL_PATH = \"weights/\"+model.name+\".h5\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.compile(\n",
    "    optimizer = Adam(learning_rate=3e-3),\n",
    "    loss=CategoricalCrossentropy(from_logits=True),\n",
    "    metrics = ['accuracy']\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_accuracy', mode='max', patience=15, verbose=2),\n",
    "    ReduceLROnPlateau(monitor='val_accuracy', mode='max', patience=5, factor=0.1, min_lr=1e-5, verbose=2),\n",
    "    ModelCheckpoint(MODEL_PATH, monitor='val_accuracy', mode='max', \n",
    "                    verbose=2, save_best_only=True, save_weights_only=True)    \n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "End of epoch 1\n",
    "- loss: 5.5664\n",
    "- accuracy: 0.0305\n",
    "- val_loss: 4.5994\n",
    "- val_accuracy: 0.0761"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    epochs=EPOCHS,\n",
    "    validation_data=valid_dataset,\n",
    "    callbacks=callbacks,\n",
    "    verbose=1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
