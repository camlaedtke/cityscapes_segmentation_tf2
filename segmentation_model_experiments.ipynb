{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "import time\n",
    "import random\n",
    "import datetime\n",
    "import numpy as np\n",
    "from matplotlib import colors\n",
    "import matplotlib.pyplot as plt\n",
    "from IPython.display import clear_output\n",
    "%config InlineBackend.figure_format = 'retina'\n",
    "plt.style.use('ggplot')\n",
    "plt.rc('xtick',labelsize=16)\n",
    "plt.rc('ytick',labelsize=16)\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers\n",
    "from tensorflow.keras.layers import *\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.optimizers import Adam, SGD\n",
    "from tensorflow.keras.utils import plot_model\n",
    "from tensorflow.keras.optimizers.schedules import PolynomialDecay\n",
    "from tensorflow.keras.callbacks import ModelCheckpoint, ReduceLROnPlateau, EarlyStopping, TensorBoard\n",
    "from tensorflow.keras import mixed_precision\n",
    "\n",
    "from utils.plot_utils import plot_iou_trainId, plot_iou_catId\n",
    "from utils.data_utils import get_labels, parse_record, get_dataset_from_tfrecord\n",
    "# from models.hrnet_keras_logits import HRNet\n",
    "# from models.u2net_logits import U2NET\n",
    "# from models.erfnet_logits import ERFNet\n",
    "from models.hrnet_seg import HRNet\n",
    "\n",
    "from data_loader import DataLoader\n",
    "\n",
    "K.clear_session()\n",
    "physical_devices = tf.config.experimental.list_physical_devices(\"GPU\")\n",
    "tf.config.experimental.set_memory_growth(physical_devices[0], True)\n",
    "\n",
    "def enable_amp():\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    \n",
    "print(\"Tensorflow version: \", tf.__version__)\n",
    "print(physical_devices,\"\\n\")\n",
    "enable_amp() "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fine = False\n",
    "\n",
    "img_height = 384\n",
    "img_width = 768\n",
    "n_classes = 20\n",
    "BATCH_SIZE = 2\n",
    "BUFFER_SIZE = 300\n",
    "\n",
    "labels = get_labels()\n",
    "trainid2label = { label.trainId : label for label in labels }\n",
    "catid2label = { label.categoryId : label for label in labels }\n",
    "\n",
    "pipeline = DataLoader(img_height=img_height, img_width=img_width, n_classes=n_classes, sparse=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if fine:\n",
    "    train_tfrecord_dir = \"records/trainIds_train.record\"\n",
    "    test_tfrecord_dir = \"records/trainIds_val.record\"\n",
    "    TRAIN_LENGTH = 2975\n",
    "    TEST_LENGTH = 500\n",
    "    train_ds = get_dataset_from_tfrecord(train_tfrecord_dir)\n",
    "    test_ds = get_dataset_from_tfrecord(test_tfrecord_dir)\n",
    "else:\n",
    "    train_tfrecord_dir = \"records/trainIds_train_extra.record\"\n",
    "    TRAIN_LENGTH = 18000\n",
    "    TEST_LENGTH = 1998\n",
    "    all_ds = get_dataset_from_tfrecord(train_tfrecord_dir)\n",
    "    train_ds = all_ds.skip(TEST_LENGTH)\n",
    "    test_ds = all_ds.take(TEST_LENGTH) \n",
    "\n",
    "\n",
    "train = train_ds.map(pipeline.load_image_train, num_parallel_calls=tf.data.experimental.AUTOTUNE)\n",
    "test = test_ds.map(pipeline.load_image_test)\n",
    "eval = test_ds.map(pipeline.load_image_eval)\n",
    "\n",
    "train_dataset = train.shuffle(BUFFER_SIZE).batch(BATCH_SIZE).repeat()\n",
    "train_dataset = train_dataset.prefetch(buffer_size=tf.data.experimental.AUTOTUNE)\n",
    "test_dataset = test.batch(BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def label_to_rgb(mask):\n",
    "    h = mask.shape[0]\n",
    "    w = mask.shape[1]\n",
    "    mask_rgb = np.zeros((h, w, 3), dtype=np.uint8)\n",
    "    for val, key in trainid2label.items():\n",
    "        indices = mask == val\n",
    "        mask_rgb[indices.squeeze()] = key.color \n",
    "    return mask_rgb\n",
    "\n",
    "\n",
    "def display(display_list, title=True):\n",
    "    plt.figure(figsize=(15, 5), dpi=150) # dpi=200\n",
    "    if title:\n",
    "        title = ['Input Image', 'True Mask', 'Predicted Mask']\n",
    "    for i in range(len(display_list)):\n",
    "        plt.subplot(1, len(display_list), i+1)\n",
    "        if title:\n",
    "            plt.title(title[i])\n",
    "        plt.imshow(tf.keras.preprocessing.image.array_to_img(display_list[i]))\n",
    "        plt.axis('off')\n",
    "    plt.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in test.take(4): # 16\n",
    "    sample_image, sample_mask = image, mask\n",
    "\n",
    "if pipeline.sparse == False:\n",
    "    sample_mask = tf.argmax(sample_mask, axis=-1)\n",
    "sample_mask = sample_mask[..., tf.newaxis]\n",
    "sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "display([sample_image, sample_mask])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.clear_session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "model = HRNet(\n",
    "    stage1_cfg = {'NUM_MODULES': 1,'NUM_BRANCHES': 1,'BLOCK': 'BOTTLENECK','NUM_BLOCKS': [4]}, \n",
    "    stage2_cfg = {'NUM_MODULES': 1,'NUM_BRANCHES': 2,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4]},\n",
    "    stage3_cfg = {'NUM_MODULES': 4,'NUM_BRANCHES': 3,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4, 4]},\n",
    "    stage4_cfg = {'NUM_MODULES': 3,'NUM_BRANCHES': 4,'BLOCK': 'BASIC',     'NUM_BLOCKS': [4, 4, 4, 4]},\n",
    "    input_height = img_height, \n",
    "    input_width = img_width, \n",
    "    n_classes = n_classes, \n",
    "    W = 32\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "if fine:\n",
    "    MODEL_PATH = \"weights/\"+model.name+\".h5\"\n",
    "else:\n",
    "    MODEL_PATH = \"weights/\"+model.name+\"_coarse.h5\"\n",
    "\n",
    "# model.load_weights(\"weights/\"+model.name+\"_coarse.h5\")\n",
    "# model.load_weights(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_mask(pred_mask):\n",
    "    pred_mask = tf.squeeze(pred_mask)\n",
    "    pred_mask = tf.argmax(pred_mask, axis=-1)\n",
    "    pred_mask = pred_mask[..., tf.newaxis]\n",
    "    pred_mask = label_to_rgb(pred_mask.numpy())\n",
    "    return pred_mask\n",
    "\n",
    "\n",
    "def show_predictions():        \n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    if \"U2Net\" in model.name:\n",
    "        pred_mask = pred_mask[0]\n",
    "    display([sample_image, sample_mask, create_mask(pred_mask)])\n",
    "\n",
    "        \n",
    "class DisplayCallback(tf.keras.callbacks.Callback):\n",
    "    def on_epoch_end(self, epoch, logs=None):\n",
    "        clear_output(wait=True)\n",
    "        show_predictions()\n",
    "        print ('\\nSample Prediction after epoch {}\\n'.format(epoch+1))\n",
    "        \n",
    "        \n",
    "def iou_coef(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    IOU = TP / (TP + FN + FP)\n",
    "    Gets the IoU score for each class (averaged over the batch), then computes the mean\n",
    "    When smooth=1, metrics where absent classes contribute to the class mean as 1.0\n",
    "    \"\"\"\n",
    "    smooth = 1\n",
    "    iou_total = 0\n",
    "    for i in range(1, n_classes):\n",
    "        tp = tf.math.reduce_sum(y_pred[:,:,:,i] * y_true[:,:,:,i], axis=(1,2))\n",
    "        fn = tf.math.reduce_sum(y_true[:,:,:,i] * (1 - y_pred[:,:,:,i]), axis=(1,2)) \n",
    "        fp = tf.math.reduce_sum(y_pred[:,:,:,i] * (1 - y_true[:,:,:,i]), axis=(1,2)) \n",
    "        iou = tf.math.reduce_mean(tf.math.divide_no_nan(tp+smooth, tp+fn+fp+smooth), axis=0)\n",
    "        iou_total += iou\n",
    "\n",
    "    iou_macro = iou_total / (n_classes - 1)\n",
    "    return iou_macro\n",
    "\n",
    "\n",
    "\n",
    "def iou_coef_sparse(y_true, y_pred):\n",
    "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), n_classes)\n",
    "    y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
    "    smooth = 1\n",
    "    iou_total = 0\n",
    "    for i in range(1, n_classes):\n",
    "        intersection = tf.math.reduce_sum(y_true[:,:,:,i] * y_pred[:,:,:,i], axis=(1,2))\n",
    "        union = tf.math.reduce_sum(y_true[:,:,:,i] + y_pred[:,:,:,i], axis=(1,2)) \n",
    "        iou = tf.math.reduce_mean(tf.math.divide_no_nan(2.*intersection+smooth, union+smooth), axis=0)\n",
    "        iou_total += iou\n",
    "    return iou_total/(n_classes-1)\n",
    "\n",
    "\n",
    "\n",
    "def dice_coef_sparse(y_true, y_pred):\n",
    "    \"\"\"\n",
    "    DICE = (2 x TP) / (2 x TP + FN + FP)\n",
    "    Gets the IoU score for each class (averaged over the batch), then computes the mean\n",
    "    When smooth=1, metrics where absent classes contribute to the class mean as 1.0\n",
    "    \"\"\"\n",
    "    y_true = tf.one_hot(tf.cast(y_true, tf.int32), n_classes)\n",
    "    y_pred = tf.nn.softmax(y_pred, axis=-1)\n",
    "    smooth = 1\n",
    "    dice_total = 0\n",
    "    for i in range(1, n_classes):\n",
    "        intersection = tf.math.reduce_sum(y_true[:,:,:,i] * y_pred[:,:,:,i], axis=1)\n",
    "        union = tf.math.reduce_sum(y_true[:,:,:,i] + y_pred[:,:,:,i], axis=1)\n",
    "        dice = tf.math.reduce_mean(tf.math.divide_no_nan(2.*intersection+smooth, union+smooth), axis=0)\n",
    "        dice_total += dice\n",
    "    return dice_total/(n_classes-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "show_predictions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "EPOCHS = 100\n",
    "STEPS_PER_EPOCH = TRAIN_LENGTH // BATCH_SIZE \n",
    "VALIDATION_STEPS = TEST_LENGTH // BATCH_SIZE \n",
    "DECAY_STEPS = STEPS_PER_EPOCH * EPOCHS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "c_weights = [0.0,    2.602,  6.707,  3.522,  9.877, \n",
    "             9.685,  9.398,  10.288, 9.969,  4.336, \n",
    "             9.454,  7.617,  9.405,  10.359, 6.373, \n",
    "             10.231, 10.262, 10.264, 10.394, 10.094] \n",
    "\n",
    "\n",
    "def weighted_cross_entropy_loss(y_true_labels, y_pred_logits):\n",
    "    # y_true_labels: (batch_size, img_h, img_w)\n",
    "    # y_pred_logits: (batch_size, img_h, img_w, num_classes)\n",
    "    losses = tf.nn.sparse_softmax_cross_entropy_with_logits(labels=y_true_labels, logits=y_pred_logits)  \n",
    "    weights = tf.gather(c_weights, y_true_labels)  \n",
    "    losses = tf.multiply(losses, weights)\n",
    "    return tf.math.reduce_mean(losses)\n",
    "\n",
    "\n",
    "learning_rate_fn = PolynomialDecay(\n",
    "    initial_learning_rate = 1e-3,\n",
    "    decay_steps = DECAY_STEPS,\n",
    "    end_learning_rate = 1e-6,\n",
    "    power=0.9\n",
    ")\n",
    "\n",
    "\n",
    "model.compile(\n",
    "    optimizer = Adam(learning_rate=1e-4),\n",
    "    loss = weighted_cross_entropy_loss,\n",
    "    metrics = ['accuracy', iou_coef_sparse]\n",
    ")    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "callbacks = [\n",
    "    # DisplayCallback(),\n",
    "    EarlyStopping(monitor='val_iou_coef_sparse', mode='max', patience=20, verbose=2),\n",
    "    ReduceLROnPlateau(monitor='val_iou_coef_sparse', mode='max', factor=0.1, patience=5, min_lr=1e-7, verbose=2),\n",
    "    ModelCheckpoint(MODEL_PATH, monitor='val_iou_coef_sparse', verbose=2, save_best_only=True, \n",
    "                    save_weights_only=True, mode='max'),\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(train_dataset)\n",
    "print(test_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "results = model.fit(\n",
    "    train_dataset,\n",
    "    steps_per_epoch=STEPS_PER_EPOCH,\n",
    "    validation_steps=VALIDATION_STEPS,\n",
    "    epochs = EPOCHS,\n",
    "    validation_data = test_dataset,\n",
    "    callbacks = callbacks,\n",
    "    verbose = 1\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "results = model.history"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def plot_history(results, model):\n",
    "        \n",
    "    plt.figure(figsize=(15,7))\n",
    "    plt.subplot(1,3,1)  \n",
    "    if \"U2Net\" in model.name:\n",
    "        plt.plot(results.history['d0_loss'], 'r', label='Training loss') \n",
    "        plt.plot(results.history['val_d0_loss'], 'b', label='Validation loss')\n",
    "    else: \n",
    "        plt.plot(results.history['loss'], 'r', label='Training loss')\n",
    "        plt.plot(results.history['val_loss'], 'b', label='Validation loss')\n",
    "    plt.title(\"Loss: \"+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,2)\n",
    "    if \"U2Net\" in model.name:\n",
    "        plt.plot(results.history['d0_accuracy'], 'r', label='Training accuracy')\n",
    "        plt.plot(results.history['val_d0_accuracy'], 'b', label='Validation accuracy')\n",
    "    else:\n",
    "        plt.plot(results.history['accuracy'], 'r', label='Training accuracy')\n",
    "        plt.plot(results.history['val_accuracy'], 'b', label='Validation accuracy')\n",
    "    plt.title('Accuracy: '+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "\n",
    "    plt.subplot(1,3,3)\n",
    "    if \"U2Net\" in model.name:\n",
    "        plt.plot(results.history['d0_iou_coef_sparse'], 'r', label='IoU coefficient')\n",
    "        plt.plot(results.history['val_d0_iou_coef_sparse'], 'b', label='Validation IoU coefficient')\n",
    "    else:\n",
    "        plt.plot(results.history['iou_coef_sparse'], 'r', label='IoU coefficient')\n",
    "        plt.plot(results.history['val_iou_coef_sparse'], 'b', label='Validation IoU coefficient')\n",
    "    plt.title('IoU Coefficient: '+model.name, fontsize=16)\n",
    "    plt.xlabel('Epoch', fontsize=16)\n",
    "    plt.legend(prop={'size': 14})\n",
    "    if fine:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_learning_curves.png\")\n",
    "    else:\n",
    "        plt.savefig(\"plots/\"+model.name+\"_learning_curves_coarse.png\")\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_history(results, model)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Evaluation\n",
    "\n",
    "For evaluation IoU scores, we need to calculate the *hard* IoU score as opposed to the *soft* IoU score. We used soft IoU function for training loss. Also, we want to resize everything to the original resolution. \n",
    "\n",
    "See this [link](https://www.jeremyjordan.me/semantic-segmentation/)\n",
    "\n",
    "\n",
    "Variations of mean IoU score\n",
    "- micro: True positives, false positives, and false negatives are computed globally\n",
    "- macro: True positives, false positives, and false negatives are computed for each class and their unweighted mean is returned\n",
    "- weighted: Metrics are computed for each class and returns the mean weighted by the number of true instances in each class "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# K.clear_session()\n",
    "# model = U2NET(input_height=img_height, input_width=img_width, n_classes=20)\n",
    "# model = ERFNet(input_height=img_height, input_width=img_width, n_classes=20)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# model.load_weights(\"weights/U2Net_latest.h5\")\n",
    "# model.load_weights(\"weights/ERFNet.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model.load_weights(MODEL_PATH)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate_iou(model, dataset, n_samples):\n",
    "    \n",
    "    inf_times = np.zeros((n_samples, ))\n",
    "    miou_op =  tf.keras.metrics.MeanIoU(num_classes=n_classes-1)\n",
    "    \n",
    "    for idx, (image, mask) in enumerate(dataset):\n",
    "        print(\"\\r Predicting {} \\ {} \".format(idx+1, n_samples), end='')\n",
    "        \n",
    "        X = np.expand_dims(image.numpy(), axis=0)\n",
    "        y_true = np.expand_dims(mask.numpy(), axis=0)\n",
    "        \n",
    "        t_start = time.time()\n",
    "        y_pred = model.predict(X)\n",
    "        t_end = time.time()\n",
    "        t_inf = t_end-t_start\n",
    "        \n",
    "        inf_times[idx] = t_inf\n",
    "        \n",
    "        if \"U2Net\" in model.name:\n",
    "            y_pred = y_pred[0]\n",
    "            \n",
    "        y_pred = tf.image.resize(y_pred, (1024, 2048))\n",
    "        threshold = tf.math.reduce_max(y_pred, axis=-1, keepdims=True)\n",
    "        y_pred = tf.logical_and(y_pred >= threshold, tf.abs(y_pred) > 1e-12)\n",
    "        \n",
    "        y_pred = tf.cast(tf.squeeze(y_pred, axis=0), tf.int32)\n",
    "        y_true = tf.cast(tf.squeeze(y_true, axis=0), tf.int32)\n",
    "        \n",
    "        if pipeline.sparse == False:\n",
    "            y_true = tf.argmax(y_true[:,:,1:], axis=-1)\n",
    "        else:\n",
    "            y_true = tf.one_hot(tf.cast(y_true, tf.int32), n_classes)\n",
    "            y_true = tf.argmax(y_true[:,:,1:], axis=-1)\n",
    "        y_pred = tf.argmax(y_pred[:,:,1:], axis=-1)\n",
    "                \n",
    "        miou_op.update_state(y_true, y_pred)\n",
    "        \n",
    "        if idx == (n_samples-1):\n",
    "            break\n",
    "    \n",
    "    print(\"Average inference time: {:.2f}s\".format(np.mean(inf_times)))\n",
    "            \n",
    "    return miou_op"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "miou_op = evaluate_iou(model=model, dataset=eval, n_samples=TEST_LENGTH)\n",
    "iou_mean = miou_op.result().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "union_int = np.sum(miou_op.get_weights()[0], axis=0)+np.sum(miou_op.get_weights()[0], axis=1)\n",
    "inters = np.diag(miou_op.get_weights()[0])\n",
    "ious = inters / (union_int-inters+1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_iou_trainId(\n",
    "    trainId_label_map=trainid2label,\n",
    "    catId_label_map=catid2label, \n",
    "    n_classes=n_classes, \n",
    "    iou_class=ious,\n",
    "    model=model, \n",
    "    iou_mean=iou_mean,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def visualize_confusion_matrix(confusion, metric, label_classes, model):\n",
    "    plt.figure(figsize=(14,14))\n",
    "    plt.title(\"{} Confusion Matrix, with Mean IoU = {:.3f}\".format(model.name, metric), fontsize=22)\n",
    "    plt.imshow(confusion)\n",
    "    ax, fig = plt.gca(), plt.gcf()\n",
    "    plt.xticks(np.arange(len(label_classes)), label_classes)\n",
    "    plt.yticks(np.arange(len(label_classes)), label_classes)\n",
    "    # set horizontal alignment mode (left, right or center) and rotation mode(anchor or default)\n",
    "    plt.setp(ax.get_xticklabels(), rotation=-90, ha=\"center\", rotation_mode=\"default\")\n",
    "    # avoid top and bottom part of heatmap been cut\n",
    "    ax.set_xticks(np.arange(len(label_classes) + 1) - .5, minor=True)\n",
    "    ax.set_yticks(np.arange(len(label_classes) + 1) - .5, minor=True)\n",
    "    ax.tick_params(which=\"minor\", bottom=False, left=False)\n",
    "    ax.grid(False)\n",
    "    fig.tight_layout()\n",
    "    plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "visualize_confusion_matrix(\n",
    "    confusion = miou_op.get_weights()[0] / np.sum(miou_op.get_weights()[0], axis=0), \n",
    "    metric = iou_mean, \n",
    "    label_classes = [trainid2label[i].name for i in range(1, n_classes)],\n",
    "    model = model\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def show_predictions(sample_image, sample_mask):        \n",
    "    pred_mask = model.predict(sample_image[tf.newaxis, ...])\n",
    "    if \"U2Net\" in model.name:\n",
    "        pred_mask = pred_mask[0]\n",
    "    # sample_mask = tf.argmax(sample_mask, axis=-1)\n",
    "    sample_mask = sample_mask[..., tf.newaxis]\n",
    "    sample_mask = label_to_rgb(sample_mask.numpy())\n",
    "    display([sample_image, sample_mask, create_mask(pred_mask)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in test.take(96): # 16\n",
    "    sample_image, sample_mask = image, mask\n",
    "show_predictions(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in test.take(4): # 16\n",
    "    sample_image, sample_mask = image, mask\n",
    "show_predictions(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for image, mask in test.take(27): # 16\n",
    "    sample_image, sample_mask = image, mask\n",
    "show_predictions(sample_image, sample_mask)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
